{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brain MRI Tumor Segmentation — All-in-One Notebook\n",
        "\n",
        "Run this cell to install dependencies if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch nibabel albumentations scikit-image matplotlib scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## config.py\n",
        "\n",
        "Running content from `config.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "CONFIG — Central Configuration for Brain MRI Tumor Segmentation\n",
        "============================================================================\n",
        "All hyperparameters, paths, and device settings in one place.\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# ── Paths ──────────────────────────────────────────────────────────────────\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DATA_ROOT = PROJECT_ROOT / \"Data\"\n",
        "CHECKPOINT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
        "LOG_FILE = PROJECT_ROOT / \"training_log.csv\"\n",
        "\n",
        "# Create directories\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ── Device ─────────────────────────────────────────────────────────────────\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_WORKERS = 2       # 2 for laptop (fewer CPU cores, shared thermal)\n",
        "PIN_MEMORY = torch.cuda.is_available()\n",
        "GPU_VRAM_GB = 4       # RTX 3050 Laptop GPU\n",
        "\n",
        "# ── Data ───────────────────────────────────────────────────────────────────\n",
        "IMAGE_SIZE = 224               # Optimized for 4GB VRAM (224 vs 256 saves ~25% memory)\n",
        "NUM_MODALITIES = 4             # T1c, T1n, T2-FLAIR, T2w\n",
        "MODALITY_SUFFIXES = [          # Order matters — stacked as input channels\n",
        "    \"brain_t1c\",\n",
        "    \"brain_t1n\",\n",
        "    \"brain_t2f\",\n",
        "    \"brain_t2w\",\n",
        "]\n",
        "MASK_SUFFIX = \"tumorMask\"\n",
        "\n",
        "# Subset ratio for prototyping (0.15 = 15% of patients)\n",
        "SUBSET_RATIO = 0.15\n",
        "\n",
        "# Minimum brain tissue fraction in a slice to include it\n",
        "# (filters out mostly-empty slices that add noise)\n",
        "MIN_BRAIN_FRACTION = 0.02\n",
        "\n",
        "# Train/Val/Test split ratios (patient-level, not slice-level)\n",
        "TRAIN_RATIO = 0.80\n",
        "VAL_RATIO = 0.10\n",
        "TEST_RATIO = 0.10\n",
        "\n",
        "# ── Training ───────────────────────────────────────────────────────────────\n",
        "BATCH_SIZE = 4                 # Small batch for 4GB VRAM\n",
        "GRAD_ACCUMULATION_STEPS = 8    # Effective batch = 4 * 8 = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EPOCHS = 100\n",
        "WARMUP_EPOCHS = 5\n",
        "GRADIENT_CHECKPOINTING = True  # Saves ~30% VRAM by recomputing activations\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "USE_AMP = True                 # Mixed precision (FP16)\n",
        "\n",
        "# ── Model ──────────────────────────────────────────────────────────────────\n",
        "ENCODER_NAME = \"efficientnet-b0\"  # B0 instead of B3 — fits 4GB VRAM comfortably\n",
        "ENCODER_WEIGHTS = \"imagenet\"      # Pre-trained weights\n",
        "NUM_CLASSES = 1                   # Binary segmentation (tumor / no tumor)\n",
        "\n",
        "# ── Augmentation ───────────────────────────────────────────────────────────\n",
        "AUG_ROTATION_LIMIT = 15        # degrees\n",
        "AUG_BRIGHTNESS_LIMIT = 0.1\n",
        "AUG_CONTRAST_LIMIT = 0.1\n",
        "AUG_ELASTIC_ALPHA = 50\n",
        "AUG_ELASTIC_SIGMA = 10\n",
        "\n",
        "# ── Logging ────────────────────────────────────────────────────────────────\n",
        "PRINT_EVERY_N_BATCHES = 50     # Print progress every N batches\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## augmentations.py\n",
        "\n",
        "Running content from `augmentations.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "AUGMENTATIONS — MRI-Appropriate On-The-Fly Data Augmentation\n",
        "============================================================================\n",
        "Uses albumentations for fast, GPU-friendly augmentations.\n",
        "All transforms are applied during DataLoader iteration — no extra disk usage.\n",
        "Medical imaging constraints:\n",
        "  - No heavy warping that distorts anatomy\n",
        "  - Conservative rotation (±15°)\n",
        "  - Mild brightness/contrast jitter\n",
        "  - Elastic deformation (helps segmentation generalization)\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import config\n",
        "\n",
        "\n",
        "def get_train_transforms():\n",
        "    \"\"\"\n",
        "    Training augmentations — applied on-the-fly to each 2D slice.\n",
        "    Both image (4-channel) and mask (1-channel) are transformed together\n",
        "    to maintain spatial alignment.\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        # -- Spatial transforms (applied to both image and mask) --\n",
        "        A.Resize(config.IMAGE_SIZE, config.IMAGE_SIZE),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.Rotate(\n",
        "            limit=config.AUG_ROTATION_LIMIT,\n",
        "            border_mode=0,  # zero-padding at borders\n",
        "            p=0.5\n",
        "        ),\n",
        "        # Elastic deformation — good for segmentation, mild settings\n",
        "        A.ElasticTransform(\n",
        "            alpha=config.AUG_ELASTIC_ALPHA,\n",
        "            sigma=config.AUG_ELASTIC_SIGMA,\n",
        "            p=0.3\n",
        "        ),\n",
        "        # -- Intensity transforms (applied to image only, not mask) --\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=config.AUG_BRIGHTNESS_LIMIT,\n",
        "            contrast_limit=config.AUG_CONTRAST_LIMIT,\n",
        "            p=0.4\n",
        "        ),\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
        "        A.GaussNoise(p=0.2),\n",
        "        # Convert to tensor\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def get_val_transforms():\n",
        "    \"\"\"\n",
        "    Validation/test transforms — deterministic, no randomness.\n",
        "    Only resize + tensor conversion.\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(config.IMAGE_SIZE, config.IMAGE_SIZE),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## dataset.py\n",
        "\n",
        "Running content from `dataset.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "DATASET — Memory-Efficient Brain MRI Dataset with 2D Slice Extraction\n",
        "============================================================================\n",
        "Key design decisions:\n",
        "  1. LAZY LOADING: NIfTI volumes are NOT loaded into RAM at init time.\n",
        "     Only metadata (paths, slice indices) are cached.\n",
        "  2. ON-THE-FLY SLICING: Each __getitem__ loads only ONE 2D slice from \n",
        "     the 3D volume using nibabel's proxy object (memory-mapped).\n",
        "  3. PATIENT-LEVEL SPLIT: Train/val/test are split by patient ID, not\n",
        "     by slice, to prevent data leakage between sets.\n",
        "  4. EMPTY SLICE FILTERING: Slices with <2% brain tissue are excluded.\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import config\n",
        "from augmentations import get_train_transforms, get_val_transforms\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# HELPER: Scan dataset and build a slice index WITHOUT loading image data\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def build_slice_index(\n",
        "    data_root: Path,\n",
        "    subset_ratio: float = 1.0,\n",
        "    seed: int = 42,\n",
        "    verbose: bool = True,\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Scans the dataset folder structure and builds an index of all valid\n",
        "    2D slices across all patients/timepoints.\n",
        "    \n",
        "    Returns a list of dicts, each containing:\n",
        "      - patient_id: str\n",
        "      - timepoint: str\n",
        "      - modality_paths: dict mapping modality suffix -> file path\n",
        "      - mask_path: path to tumor mask (or None)\n",
        "      - slice_idx: int (axial slice index)\n",
        "      - has_tumor: bool (whether this slice has any tumor voxels)\n",
        "    \n",
        "    IMPORTANT: This function loads each volume BRIEFLY to check dimensions\n",
        "    and identify valid slices, then immediately releases the data.\n",
        "    Mask files are small (~30KB) and loaded to determine per-slice tumor presence.\n",
        "    \"\"\"\n",
        "    \n",
        "    # -- Step 1: Collect all patient directories --\n",
        "    patient_dirs = sorted([d for d in data_root.iterdir() if d.is_dir()])\n",
        "    \n",
        "    # -- Step 2: Apply subset sampling (patient-level) --\n",
        "    if subset_ratio < 1.0:\n",
        "        random.seed(seed)\n",
        "        n_patients = max(1, int(len(patient_dirs) * subset_ratio))\n",
        "        patient_dirs = sorted(random.sample(patient_dirs, n_patients))\n",
        "        if verbose:\n",
        "            print(f\"[SUBSET] Using {n_patients}/{len(list(data_root.iterdir()))} \"\n",
        "                  f\"patients ({subset_ratio*100:.0f}%)\")\n",
        "    \n",
        "    slice_index = []\n",
        "    total_slices = 0\n",
        "    tumor_slices = 0\n",
        "    skipped_empty = 0\n",
        "    \n",
        "    for i, patient_dir in enumerate(patient_dirs):\n",
        "        patient_id = patient_dir.name\n",
        "        \n",
        "        for tp_dir in sorted(patient_dir.iterdir()):\n",
        "            if not tp_dir.is_dir():\n",
        "                continue\n",
        "            timepoint = tp_dir.name\n",
        "            \n",
        "            # -- Collect modality file paths --\n",
        "            modality_paths = {}\n",
        "            mask_path = None\n",
        "            \n",
        "            for f in tp_dir.iterdir():\n",
        "                if not f.is_file() or not f.name.endswith('.nii.gz'):\n",
        "                    continue\n",
        "                \n",
        "                fname = f.name.replace('.nii.gz', '')\n",
        "                for mod in config.MODALITY_SUFFIXES:\n",
        "                    if fname.endswith(mod):\n",
        "                        modality_paths[mod] = f\n",
        "                        break\n",
        "                \n",
        "                if config.MASK_SUFFIX in fname:\n",
        "                    mask_path = f\n",
        "            \n",
        "            # Skip if not all 4 modalities are present\n",
        "            if len(modality_paths) != config.NUM_MODALITIES:\n",
        "                if verbose:\n",
        "                    print(f\"[WARN] Missing modalities in {patient_id}/{timepoint}, skipping\")\n",
        "                continue\n",
        "            \n",
        "            # -- Load ONE modality header to get volume dimensions --\n",
        "            first_mod_path = list(modality_paths.values())[0]\n",
        "            try:\n",
        "                nii = nib.load(str(first_mod_path))\n",
        "                vol_shape = nii.shape  # e.g., (240, 240, 155)\n",
        "                num_slices = vol_shape[2]  # axial slices\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"[WARN] Failed to read {first_mod_path}: {e}\")\n",
        "                continue\n",
        "            \n",
        "            # -- Load mask to determine per-slice tumor presence --\n",
        "            # Masks are very small (~30KB compressed) so this is fast\n",
        "            mask_data = None\n",
        "            if mask_path is not None:\n",
        "                try:\n",
        "                    mask_nii = nib.load(str(mask_path))\n",
        "                    mask_data = mask_nii.get_fdata(dtype=np.float32)\n",
        "                except Exception as e:\n",
        "                    if verbose:\n",
        "                        print(f\"[WARN] Failed to read mask {mask_path}: {e}\")\n",
        "            \n",
        "            # -- Also load one modality to check brain content per slice --\n",
        "            # (We only check sum > threshold, very fast)\n",
        "            try:\n",
        "                ref_data = nii.get_fdata(dtype=np.float32)\n",
        "            except Exception:\n",
        "                continue\n",
        "            \n",
        "            # -- Build slice entries --\n",
        "            for slice_idx in range(num_slices):\n",
        "                # Check if slice has enough brain tissue\n",
        "                ref_slice = ref_data[:, :, slice_idx]\n",
        "                brain_fraction = np.count_nonzero(ref_slice) / ref_slice.size\n",
        "                \n",
        "                if brain_fraction < config.MIN_BRAIN_FRACTION:\n",
        "                    skipped_empty += 1\n",
        "                    continue\n",
        "                \n",
        "                # Check tumor presence in this slice\n",
        "                has_tumor = False\n",
        "                if mask_data is not None:\n",
        "                    mask_slice = mask_data[:, :, slice_idx]\n",
        "                    has_tumor = np.any(mask_slice > 0)\n",
        "                \n",
        "                slice_entry = {\n",
        "                    \"patient_id\": patient_id,\n",
        "                    \"timepoint\": timepoint,\n",
        "                    \"modality_paths\": {k: str(v) for k, v in modality_paths.items()},\n",
        "                    \"mask_path\": str(mask_path) if mask_path else None,\n",
        "                    \"slice_idx\": slice_idx,\n",
        "                    \"has_tumor\": has_tumor,\n",
        "                    \"vol_shape\": vol_shape,\n",
        "                }\n",
        "                slice_index.append(slice_entry)\n",
        "                total_slices += 1\n",
        "                if has_tumor:\n",
        "                    tumor_slices += 1\n",
        "            \n",
        "            # Release memory immediately\n",
        "            del ref_data, mask_data\n",
        "        \n",
        "        if verbose and (i + 1) % 20 == 0:\n",
        "            print(f\"  Scanned {i+1}/{len(patient_dirs)} patients...\")\n",
        "    \n",
        "    if verbose:\n",
        "        non_tumor = total_slices - tumor_slices\n",
        "        print(f\"\\n[INDEX] Slice index built:\")\n",
        "        print(f\"  Total valid slices: {total_slices}\")\n",
        "        print(f\"  Tumor slices:       {tumor_slices} ({tumor_slices/max(1,total_slices)*100:.1f}%)\")\n",
        "        print(f\"  Non-tumor slices:   {non_tumor} ({non_tumor/max(1,total_slices)*100:.1f}%)\")\n",
        "        print(f\"  Skipped empty:      {skipped_empty}\")\n",
        "    \n",
        "    return slice_index\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# HELPER: Patient-level train/val/test split\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def patient_split(\n",
        "    slice_index: List[Dict],\n",
        "    train_ratio: float = 0.8,\n",
        "    val_ratio: float = 0.1,\n",
        "    test_ratio: float = 0.1,\n",
        "    seed: int = 42,\n",
        ") -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
        "    \"\"\"\n",
        "    Splits slice_index into train/val/test by PATIENT ID.\n",
        "    This prevents data leakage — no patient appears in multiple splits.\n",
        "    \"\"\"\n",
        "    # Group slices by patient\n",
        "    patients = defaultdict(list)\n",
        "    for entry in slice_index:\n",
        "        patients[entry[\"patient_id\"]].append(entry)\n",
        "    \n",
        "    patient_ids = sorted(patients.keys())\n",
        "    random.seed(seed)\n",
        "    random.shuffle(patient_ids)\n",
        "    \n",
        "    n = len(patient_ids)\n",
        "    n_train = int(n * train_ratio)\n",
        "    n_val = int(n * val_ratio)\n",
        "    \n",
        "    train_pids = set(patient_ids[:n_train])\n",
        "    val_pids = set(patient_ids[n_train:n_train + n_val])\n",
        "    test_pids = set(patient_ids[n_train + n_val:])\n",
        "    \n",
        "    train_slices = [e for e in slice_index if e[\"patient_id\"] in train_pids]\n",
        "    val_slices = [e for e in slice_index if e[\"patient_id\"] in val_pids]\n",
        "    test_slices = [e for e in slice_index if e[\"patient_id\"] in test_pids]\n",
        "    \n",
        "    print(f\"\\n[SPLIT] Patient-level split (no leakage):\")\n",
        "    print(f\"  Train: {len(train_pids)} patients, {len(train_slices)} slices\")\n",
        "    print(f\"  Val:   {len(val_pids)} patients, {len(val_slices)} slices\")\n",
        "    print(f\"  Test:  {len(test_pids)} patients, {len(test_slices)} slices\")\n",
        "    \n",
        "    return train_slices, val_slices, test_slices\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# MAIN DATASET CLASS\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Memory-efficient PyTorch Dataset for brain MRI tumor segmentation.\n",
        "    \n",
        "    Each sample is a 2D axial slice with:\n",
        "      - Input:  (4, H, W) tensor — 4 MRI modalities stacked as channels\n",
        "      - Target: (1, H, W) tensor — binary tumor mask\n",
        "    \n",
        "    Key features:\n",
        "      - Lazy loading: only the requested slice is loaded per __getitem__\n",
        "      - On-the-fly augmentation via albumentations\n",
        "      - Per-modality intensity normalization (z-score)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        slice_index: List[Dict],\n",
        "        transform=None,\n",
        "        normalize: bool = True,\n",
        "    ):\n",
        "        self.slice_index = slice_index\n",
        "        self.transform = transform\n",
        "        self.normalize = normalize\n",
        "        \n",
        "        # Cache for loaded volumes (LRU-style, limited to save RAM)\n",
        "        # Key: modality_path, Value: nibabel proxy image\n",
        "        # We don't cache pixel data — only the nib object for fast slicing\n",
        "        self._nii_cache = {}\n",
        "        self._cache_max_size = 50  # Keep at most 50 nii objects cached\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.slice_index)\n",
        "    \n",
        "    def _load_nii(self, path: str):\n",
        "        \"\"\"Load a NIfTI file, using cache to avoid repeated disk reads.\"\"\"\n",
        "        if path not in self._nii_cache:\n",
        "            # Evict oldest if cache full\n",
        "            if len(self._nii_cache) >= self._cache_max_size:\n",
        "                oldest_key = next(iter(self._nii_cache))\n",
        "                del self._nii_cache[oldest_key]\n",
        "            self._nii_cache[path] = nib.load(path)\n",
        "        return self._nii_cache[path]\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        entry = self.slice_index[idx]\n",
        "        slice_idx = entry[\"slice_idx\"]\n",
        "        \n",
        "        # ── Load 4 modality slices ─────────────────────────────────────\n",
        "        channels = []\n",
        "        for mod in config.MODALITY_SUFFIXES:\n",
        "            nii = self._load_nii(entry[\"modality_paths\"][mod])\n",
        "            # get_fdata loads data; we take only the slice we need\n",
        "            vol = nii.dataobj[..., slice_idx].astype(np.float32)\n",
        "            channels.append(vol)\n",
        "        \n",
        "        # Stack as (H, W, 4) for albumentations (expects HWC)\n",
        "        image = np.stack(channels, axis=-1)  # (H, W, 4)\n",
        "        \n",
        "        # ── Load mask slice ────────────────────────────────────────────\n",
        "        if entry[\"mask_path\"] is not None:\n",
        "            mask_nii = self._load_nii(entry[\"mask_path\"])\n",
        "            mask = mask_nii.dataobj[..., slice_idx].astype(np.float32)\n",
        "            # Binarize mask (any tumor label > 0 becomes 1)\n",
        "            mask = (mask > 0).astype(np.float32)\n",
        "        else:\n",
        "            # No mask = no tumor\n",
        "            mask = np.zeros(image.shape[:2], dtype=np.float32)\n",
        "        \n",
        "        # ── Normalize per-modality (z-score) ───────────────────────────\n",
        "        if self.normalize:\n",
        "            for c in range(image.shape[-1]):\n",
        "                ch = image[:, :, c]\n",
        "                # Only normalize on non-zero voxels (brain region)\n",
        "                nonzero = ch[ch > 0]\n",
        "                if len(nonzero) > 0:\n",
        "                    mean = nonzero.mean()\n",
        "                    std = nonzero.std() + 1e-8\n",
        "                    ch[ch > 0] = (ch[ch > 0] - mean) / std\n",
        "                image[:, :, c] = ch\n",
        "        \n",
        "        # ── Apply augmentations ────────────────────────────────────────\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]  # (4, H, W) tensor\n",
        "            mask = transformed[\"mask\"]    # (H, W) tensor\n",
        "        else:\n",
        "            # Manual conversion to tensor if no transform\n",
        "            image = torch.from_numpy(image.transpose(2, 0, 1))  # (4, H, W)\n",
        "            mask = torch.from_numpy(mask)\n",
        "        \n",
        "        # Ensure mask has channel dimension: (1, H, W)\n",
        "        if mask.ndim == 2:\n",
        "            mask = mask.unsqueeze(0)\n",
        "        \n",
        "        return image.float(), mask.float()\n",
        "    \n",
        "    def get_tumor_weights(self) -> List[float]:\n",
        "        \"\"\"\n",
        "        Returns per-sample weights for WeightedRandomSampler.\n",
        "        Tumor slices get higher weight to balance class distribution.\n",
        "        \"\"\"\n",
        "        tumor_count = sum(1 for e in self.slice_index if e[\"has_tumor\"])\n",
        "        non_tumor_count = len(self.slice_index) - tumor_count\n",
        "        \n",
        "        if tumor_count == 0 or non_tumor_count == 0:\n",
        "            return [1.0] * len(self.slice_index)\n",
        "        \n",
        "        # Weight inversely proportional to class frequency\n",
        "        w_tumor = len(self.slice_index) / (2.0 * tumor_count)\n",
        "        w_non_tumor = len(self.slice_index) / (2.0 * non_tumor_count)\n",
        "        \n",
        "        weights = []\n",
        "        for entry in self.slice_index:\n",
        "            weights.append(w_tumor if entry[\"has_tumor\"] else w_non_tumor)\n",
        "        \n",
        "        return weights\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# DATALOADER FACTORY\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_dataloaders(\n",
        "    subset_ratio: float = None,\n",
        "    batch_size: int = None,\n",
        "    num_workers: int = None,\n",
        "    seed: int = 42,\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Creates train/val/test DataLoaders with proper configuration.\n",
        "    \n",
        "    Returns:\n",
        "        (train_loader, val_loader, test_loader)\n",
        "    \"\"\"\n",
        "    if subset_ratio is None:\n",
        "        subset_ratio = config.SUBSET_RATIO\n",
        "    if batch_size is None:\n",
        "        batch_size = config.BATCH_SIZE\n",
        "    if num_workers is None:\n",
        "        num_workers = config.NUM_WORKERS\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"BUILDING DATA PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Step 1: Build slice index\n",
        "    print(\"\\n[1/3] Scanning dataset and building slice index...\")\n",
        "    slice_index = build_slice_index(\n",
        "        config.DATA_ROOT,\n",
        "        subset_ratio=subset_ratio,\n",
        "        seed=seed,\n",
        "    )\n",
        "    \n",
        "    # Step 2: Patient-level split\n",
        "    print(\"\\n[2/3] Splitting by patient ID...\")\n",
        "    train_idx, val_idx, test_idx = patient_split(\n",
        "        slice_index,\n",
        "        train_ratio=config.TRAIN_RATIO,\n",
        "        val_ratio=config.VAL_RATIO,\n",
        "        test_ratio=config.TEST_RATIO,\n",
        "        seed=seed,\n",
        "    )\n",
        "    \n",
        "    # Step 3: Create datasets\n",
        "    print(\"\\n[3/3] Creating DataLoaders...\")\n",
        "    train_dataset = BrainMRIDataset(train_idx, transform=get_train_transforms())\n",
        "    val_dataset = BrainMRIDataset(val_idx, transform=get_val_transforms())\n",
        "    test_dataset = BrainMRIDataset(test_idx, transform=get_val_transforms())\n",
        "    \n",
        "    # Weighted sampler for training (handles class imbalance)\n",
        "    train_weights = train_dataset.get_tumor_weights()\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=train_weights,\n",
        "        num_samples=len(train_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,  # WeightedRandomSampler replaces shuffle\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=config.PIN_MEMORY,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    \n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=config.PIN_MEMORY,\n",
        "    )\n",
        "    \n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=config.PIN_MEMORY,\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n[READY] DataLoaders created:\")\n",
        "    print(f\"  Train: {len(train_dataset)} slices, {len(train_loader)} batches\")\n",
        "    print(f\"  Val:   {len(val_dataset)} slices, {len(val_loader)} batches\")\n",
        "    print(f\"  Test:  {len(test_dataset)} slices, {len(test_loader)} batches\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Workers: {num_workers}\")\n",
        "    print(f\"  Pin memory: {config.PIN_MEMORY}\")\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# QUICK TEST (run this file directly to verify pipeline)\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "if False: # __name__ == \"__main__\":\n",
        "    import sys\n",
        "    sys.stdout.reconfigure(encoding='utf-8')\n",
        "    \n",
        "    print(\"Testing data pipeline with 5% subset...\\n\")\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(\n",
        "        subset_ratio=0.05,\n",
        "        batch_size=4,\n",
        "        num_workers=0,  # 0 workers for testing\n",
        "    )\n",
        "    \n",
        "    # Grab one batch\n",
        "    print(\"\\nLoading first batch...\")\n",
        "    images, masks = next(iter(train_loader))\n",
        "    print(f\"\\n[BATCH]\")\n",
        "    print(f\"  Images shape: {images.shape}\")    # Expected: (4, 4, 256, 256)\n",
        "    print(f\"  Masks shape:  {masks.shape}\")      # Expected: (4, 1, 256, 256)\n",
        "    print(f\"  Images dtype: {images.dtype}\")\n",
        "    print(f\"  Masks dtype:  {masks.dtype}\")\n",
        "    print(f\"  Images range: [{images.min():.4f}, {images.max():.4f}]\")\n",
        "    print(f\"  Masks unique: {masks.unique().tolist()}\")\n",
        "    print(f\"  Tumor pixels in batch: {masks.sum().item():.0f}\")\n",
        "    print(\"\\nData pipeline test PASSED!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## model.py\n",
        "\n",
        "Running content from `model.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "MODEL — 2D U-Net with EfficientNet Encoder for Brain Tumor Segmentation\n",
        "============================================================================\n",
        "Architecture:\n",
        "  - Encoder: EfficientNet-B0 (pretrained on ImageNet, optimized for 4GB VRAM)\n",
        "  - Decoder: U-Net decoder with skip connections\n",
        "  - Input: (B, 4, H, W) — 4 MRI modalities as channels\n",
        "  - Output: (B, 1, H, W) — binary tumor mask (sigmoid activated)\n",
        "  \n",
        "Uses segmentation_models_pytorch (smp) for clean implementation.\n",
        "The first conv layer is adapted from 3-channel (ImageNet) to 4-channel input.\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as cp\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import config\n",
        "\n",
        "\n",
        "class BrainTumorSegModel(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net segmentation model for brain tumor detection.\n",
        "    \n",
        "    Also includes a classification head that outputs a binary\n",
        "    cancer/no-cancer prediction from the encoder features.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder_name: str = None,\n",
        "        encoder_weights: str = None,\n",
        "        in_channels: int = None,\n",
        "        num_classes: int = None,\n",
        "        gradient_checkpointing: bool = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        encoder_name = encoder_name or config.ENCODER_NAME\n",
        "        encoder_weights = encoder_weights or config.ENCODER_WEIGHTS\n",
        "        in_channels = in_channels or config.NUM_MODALITIES\n",
        "        num_classes = num_classes or config.NUM_CLASSES\n",
        "        self.use_gradient_checkpointing = (\n",
        "            gradient_checkpointing if gradient_checkpointing is not None\n",
        "            else getattr(config, 'GRADIENT_CHECKPOINTING', False)\n",
        "        )\n",
        "        \n",
        "        # ── Segmentation backbone (U-Net with EfficientNet encoder) ────\n",
        "        self.segmentation_model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=in_channels,\n",
        "            classes=num_classes,\n",
        "            activation=None,  # We apply sigmoid in forward/loss\n",
        "        )\n",
        "        \n",
        "        # Enable gradient checkpointing on encoder to save VRAM\n",
        "        if self.use_gradient_checkpointing:\n",
        "            self._enable_gradient_checkpointing()\n",
        "        \n",
        "        # ── Classification head (from encoder bottleneck features) ─────\n",
        "        # Get the encoder output channels from smp\n",
        "        encoder_channels = self.segmentation_model.encoder.out_channels\n",
        "        bottleneck_channels = encoder_channels[-1]  # Deepest feature map\n",
        "        \n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),        # Global average pooling\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(bottleneck_channels, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1),               # Binary: cancer / no cancer\n",
        "        )\n",
        "    \n",
        "    def _enable_gradient_checkpointing(self):\n",
        "        \"\"\"Enable gradient checkpointing on encoder blocks to save ~30% VRAM.\"\"\"\n",
        "        encoder = self.segmentation_model.encoder\n",
        "        for name, module in encoder.named_children():\n",
        "            if hasattr(module, 'gradient_checkpointing'):\n",
        "                module.gradient_checkpointing = True\n",
        "            # Wrap major encoder blocks with checkpointing\n",
        "            for child_name, child in module.named_children():\n",
        "                if isinstance(child, nn.Sequential) and len(list(child.children())) > 0:\n",
        "                    original_forward = child.forward\n",
        "                    def make_ckpt_forward(mod):\n",
        "                        orig = mod.forward\n",
        "                        def ckpt_forward(*args, **kwargs):\n",
        "                            if self.training:\n",
        "                                return cp.checkpoint(orig, *args, use_reentrant=False, **kwargs)\n",
        "                            return orig(*args, **kwargs)\n",
        "                        return ckpt_forward\n",
        "                    child.forward = make_ckpt_forward(child)\n",
        "    \n",
        "    def forward(self, x, return_classification=False):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        \n",
        "        Args:\n",
        "            x: (B, 4, H, W) input tensor\n",
        "            return_classification: if True, also return classification logits\n",
        "            \n",
        "        Returns:\n",
        "            seg_logits: (B, 1, H, W) segmentation logits (pre-sigmoid)\n",
        "            cls_logits: (B, 1) classification logits (only if return_classification)\n",
        "        \"\"\"\n",
        "        # Use the full segmentation model's forward for segmentation output\n",
        "        seg_logits = self.segmentation_model(x)\n",
        "        \n",
        "        if return_classification:\n",
        "            # Separately get encoder features for classification head\n",
        "            features = self.segmentation_model.encoder(x)\n",
        "            cls_logits = self.classification_head(features[-1])\n",
        "            return seg_logits, cls_logits\n",
        "        \n",
        "        return seg_logits\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Inference-mode prediction with sigmoid activation.\n",
        "        Returns:\n",
        "            seg_probs: (B, 1, H, W) probabilities [0, 1]\n",
        "            cls_probs: (B, 1) classification probabilities [0, 1]\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            seg_logits, cls_logits = self.forward(x, return_classification=True)\n",
        "            seg_probs = torch.sigmoid(seg_logits)\n",
        "            cls_probs = torch.sigmoid(cls_logits)\n",
        "        return seg_probs, cls_probs\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# LOSS FUNCTIONS\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Dice Loss + Binary Cross-Entropy Loss.\n",
        "    \n",
        "    Dice Loss: directly optimizes the Dice coefficient (overlap metric).\n",
        "    BCE Loss: provides stable gradient signal, especially for small tumors.\n",
        "    \n",
        "    Combined loss = alpha * DiceLoss + (1 - alpha) * BCELoss\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha: float = 0.5, smooth: float = 1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.smooth = smooth\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    def dice_loss(self, logits, targets):\n",
        "        \"\"\"Computes Dice loss from logits.\"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "        \n",
        "        # Flatten spatial dimensions\n",
        "        probs_flat = probs.view(-1)\n",
        "        targets_flat = targets.view(-1)\n",
        "        \n",
        "        intersection = (probs_flat * targets_flat).sum()\n",
        "        dice = (2.0 * intersection + self.smooth) / (\n",
        "            probs_flat.sum() + targets_flat.sum() + self.smooth\n",
        "        )\n",
        "        return 1.0 - dice\n",
        "    \n",
        "    def forward(self, logits, targets):\n",
        "        dice = self.dice_loss(logits, targets)\n",
        "        bce = self.bce(logits, targets)\n",
        "        return self.alpha * dice + (1.0 - self.alpha) * bce\n",
        "\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Full loss: segmentation loss + classification loss.\n",
        "    \n",
        "    Total = seg_weight * DiceBCE(seg_logits, seg_targets)\n",
        "          + cls_weight * BCE(cls_logits, cls_targets)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, seg_weight: float = 0.8, cls_weight: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.seg_weight = seg_weight\n",
        "        self.cls_weight = cls_weight\n",
        "        self.seg_loss_fn = DiceBCELoss()\n",
        "        self.cls_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    def forward(self, seg_logits, seg_targets, cls_logits=None, cls_targets=None):\n",
        "        seg_loss = self.seg_loss_fn(seg_logits, seg_targets)\n",
        "        \n",
        "        if cls_logits is not None and cls_targets is not None:\n",
        "            cls_loss = self.cls_loss_fn(cls_logits, cls_targets)\n",
        "            total = self.seg_weight * seg_loss + self.cls_weight * cls_loss\n",
        "            return total, seg_loss, cls_loss\n",
        "        \n",
        "        return seg_loss, seg_loss, torch.tensor(0.0)\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# METRICS\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def compute_metrics(seg_logits, seg_targets, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Computes segmentation metrics from logits and targets.\n",
        "    \n",
        "    Returns dict with: dice, iou, precision, recall, accuracy\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(seg_logits)\n",
        "        preds = (probs > threshold).float()\n",
        "        \n",
        "        # Flatten\n",
        "        preds_flat = preds.view(-1)\n",
        "        targets_flat = seg_targets.view(-1)\n",
        "        \n",
        "        tp = (preds_flat * targets_flat).sum()\n",
        "        fp = (preds_flat * (1 - targets_flat)).sum()\n",
        "        fn = ((1 - preds_flat) * targets_flat).sum()\n",
        "        tn = ((1 - preds_flat) * (1 - targets_flat)).sum()\n",
        "        \n",
        "        smooth = 1e-7\n",
        "        \n",
        "        dice = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
        "        iou = (tp + smooth) / (tp + fp + fn + smooth)\n",
        "        precision = (tp + smooth) / (tp + fp + smooth)\n",
        "        recall = (tp + smooth) / (tp + fn + smooth)\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn + smooth)\n",
        "        \n",
        "        return {\n",
        "            \"dice\": dice.item(),\n",
        "            \"iou\": iou.item(),\n",
        "            \"precision\": precision.item(),\n",
        "            \"recall\": recall.item(),\n",
        "            \"accuracy\": accuracy.item(),\n",
        "        }\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# QUICK TEST\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "if False: # __name__ == \"__main__\":\n",
        "    print(\"Testing model architecture...\")\n",
        "    \n",
        "    model = BrainTumorSegModel()\n",
        "    \n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parameters:     {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "    \n",
        "    # Test forward pass\n",
        "    x = torch.randn(2, 4, 256, 256)\n",
        "    \n",
        "    # Segmentation only\n",
        "    seg_out = model(x)\n",
        "    print(f\"\\nSegmentation output:    {seg_out.shape}\")\n",
        "    \n",
        "    # Segmentation + Classification\n",
        "    seg_out, cls_out = model(x, return_classification=True)\n",
        "    print(f\"Segmentation output:    {seg_out.shape}\")\n",
        "    print(f\"Classification output:  {cls_out.shape}\")\n",
        "    \n",
        "    # Test loss\n",
        "    target_seg = torch.randint(0, 2, (2, 1, 256, 256)).float()\n",
        "    target_cls = torch.randint(0, 2, (2, 1)).float()\n",
        "    \n",
        "    loss_fn = CombinedLoss()\n",
        "    total_loss, seg_loss, cls_loss = loss_fn(seg_out, target_seg, cls_out, target_cls)\n",
        "    print(f\"\\nTotal loss: {total_loss.item():.4f}\")\n",
        "    print(f\"Seg loss:   {seg_loss.item():.4f}\")\n",
        "    print(f\"Cls loss:   {cls_loss.item():.4f}\")\n",
        "    \n",
        "    # Test metrics\n",
        "    metrics = compute_metrics(seg_out, target_seg)\n",
        "    print(f\"\\nMetrics: {metrics}\")\n",
        "    \n",
        "    print(\"\\nModel test PASSED!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train.py\n",
        "\n",
        "Running content from `train.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "TRAIN — Full Training Loop for Brain Tumor Segmentation\n",
        "============================================================================\n",
        "Features:\n",
        "  - Mixed precision training (torch.cuda.amp) — ~40% memory savings\n",
        "  - Gradient accumulation for effective larger batch sizes\n",
        "  - Cosine annealing LR scheduler with linear warmup\n",
        "  - Checkpoint saving every epoch + best model tracking\n",
        "  - Resume-from-checkpoint capability\n",
        "  - Early stopping with patience\n",
        "  - CSV metric logging every epoch\n",
        "  - Memory management (empty_cache after validation)\n",
        "  - Auto batch-size halving on OOM error\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "import numpy as np\n",
        "\n",
        "import config\n",
        "from dataset import create_dataloaders\n",
        "from model import BrainTumorSegModel, CombinedLoss, compute_metrics\n",
        "\n",
        "sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# LEARNING RATE SCHEDULER: Cosine Annealing with Linear Warmup\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
        "    \"\"\"\n",
        "    Linear warmup for warmup_epochs, then cosine decay to min_lr.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr=1e-6, last_epoch=-1):\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.total_epochs = total_epochs\n",
        "        self.min_lr = min_lr\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.last_epoch < self.warmup_epochs:\n",
        "            # Linear warmup\n",
        "            factor = (self.last_epoch + 1) / self.warmup_epochs\n",
        "            return [base_lr * factor for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            # Cosine annealing\n",
        "            progress = (self.last_epoch - self.warmup_epochs) / max(1, self.total_epochs - self.warmup_epochs)\n",
        "            factor = 0.5 * (1.0 + np.cos(np.pi * progress))\n",
        "            return [self.min_lr + (base_lr - self.min_lr) * factor for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CSV LOGGER\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class CSVLogger:\n",
        "    \"\"\"Logs metrics to a CSV file every epoch.\"\"\"\n",
        "    \n",
        "    FIELDS = [\n",
        "        \"epoch\", \"lr\", \"train_loss\", \"train_dice\", \"train_iou\",\n",
        "        \"val_loss\", \"val_dice\", \"val_iou\",\n",
        "        \"val_precision\", \"val_recall\", \"val_accuracy\",\n",
        "        \"epoch_time_sec\",\n",
        "    ]\n",
        "    \n",
        "    def __init__(self, filepath):\n",
        "        self.filepath = filepath\n",
        "        if not Path(filepath).exists():\n",
        "            with open(filepath, 'w', newline='') as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=self.FIELDS)\n",
        "                writer.writeheader()\n",
        "    \n",
        "    def log(self, row: dict):\n",
        "        with open(self.filepath, 'a', newline='') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=self.FIELDS)\n",
        "            writer.writerow({k: f\"{v:.6f}\" if isinstance(v, float) else v \n",
        "                           for k, v in row.items()})\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# TRAINING FUNCTIONS\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def train_one_epoch(\n",
        "    model, loader, criterion, optimizer, scaler, device,\n",
        "    grad_accum_steps=1, epoch=0, total_epochs=0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train for one epoch with mixed precision and gradient accumulation.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    running_iou = 0.0\n",
        "    num_batches = 0\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for batch_idx, (images, masks) in enumerate(loader):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True)\n",
        "        \n",
        "        # Classification target: 1 if any tumor pixel in the sample\n",
        "        cls_targets = (masks.sum(dim=(1, 2, 3)) > 0).float().unsqueeze(1)\n",
        "        \n",
        "        # Mixed precision forward pass\n",
        "        with autocast(device_type='cuda', enabled=config.USE_AMP):\n",
        "            seg_logits, cls_logits = model(images, return_classification=True)\n",
        "            total_loss, seg_loss, cls_loss = criterion(\n",
        "                seg_logits, masks, cls_logits, cls_targets\n",
        "            )\n",
        "            # Scale loss for gradient accumulation\n",
        "            total_loss = total_loss / grad_accum_steps\n",
        "        \n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(total_loss).backward()\n",
        "        \n",
        "        # Step optimizer every grad_accum_steps\n",
        "        if (batch_idx + 1) % grad_accum_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        # Track metrics\n",
        "        running_loss += total_loss.item() * grad_accum_steps\n",
        "        metrics = compute_metrics(seg_logits.detach(), masks)\n",
        "        running_dice += metrics[\"dice\"]\n",
        "        running_iou += metrics[\"iou\"]\n",
        "        num_batches += 1\n",
        "        \n",
        "        # Print progress\n",
        "        if (batch_idx + 1) % config.PRINT_EVERY_N_BATCHES == 0:\n",
        "            avg_loss = running_loss / num_batches\n",
        "            avg_dice = running_dice / num_batches\n",
        "            print(f\"  Epoch [{epoch+1}/{total_epochs}] \"\n",
        "                  f\"Batch [{batch_idx+1}/{len(loader)}] \"\n",
        "                  f\"Loss: {avg_loss:.4f} | Dice: {avg_dice:.4f}\")\n",
        "        \n",
        "        # Release batch from GPU\n",
        "        del images, masks, seg_logits, cls_logits\n",
        "        \n",
        "        # GPU memory report after first batch\n",
        "        if batch_idx == 0 and torch.cuda.is_available():\n",
        "            alloc = torch.cuda.memory_allocated() / 1024**2\n",
        "            reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "            total = torch.cuda.get_device_properties(0).total_memory / 1024**2\n",
        "            print(f\"  [GPU] After 1st batch: {alloc:.0f} MB allocated / \"\n",
        "                  f\"{reserved:.0f} MB reserved / {total:.0f} MB total\")\n",
        "    \n",
        "    return {\n",
        "        \"loss\": running_loss / max(num_batches, 1),\n",
        "        \"dice\": running_dice / max(num_batches, 1),\n",
        "        \"iou\": running_iou / max(num_batches, 1),\n",
        "    }\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate model on val/test set in inference mode.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_metrics = {\"dice\": 0, \"iou\": 0, \"precision\": 0, \"recall\": 0, \"accuracy\": 0}\n",
        "    num_batches = 0\n",
        "    \n",
        "    for images, masks in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True)\n",
        "        cls_targets = (masks.sum(dim=(1, 2, 3)) > 0).float().unsqueeze(1)\n",
        "        \n",
        "        with autocast(device_type='cuda', enabled=config.USE_AMP):\n",
        "            seg_logits, cls_logits = model(images, return_classification=True)\n",
        "            total_loss, _, _ = criterion(seg_logits, masks, cls_logits, cls_targets)\n",
        "        \n",
        "        running_loss += total_loss.item()\n",
        "        metrics = compute_metrics(seg_logits, masks)\n",
        "        for k in running_metrics:\n",
        "            running_metrics[k] += metrics[k]\n",
        "        num_batches += 1\n",
        "        \n",
        "        del images, masks, seg_logits, cls_logits\n",
        "    \n",
        "    n = max(num_batches, 1)\n",
        "    return {\n",
        "        \"loss\": running_loss / n,\n",
        "        \"dice\": running_metrics[\"dice\"] / n,\n",
        "        \"iou\": running_metrics[\"iou\"] / n,\n",
        "        \"precision\": running_metrics[\"precision\"] / n,\n",
        "        \"recall\": running_metrics[\"recall\"] / n,\n",
        "        \"accuracy\": running_metrics[\"accuracy\"] / n,\n",
        "    }\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CHECKPOINT MANAGEMENT\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def save_checkpoint(model, optimizer, scheduler, scaler, epoch, best_dice, filepath):\n",
        "    \"\"\"Save training state for resumption.\"\"\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
        "        \"scaler_state_dict\": scaler.state_dict(),\n",
        "        \"best_dice\": best_dice,\n",
        "    }, filepath)\n",
        "\n",
        "\n",
        "def load_checkpoint(filepath, model, optimizer=None, scheduler=None, scaler=None):\n",
        "    \"\"\"Load training state from checkpoint.\"\"\"\n",
        "    checkpoint = torch.load(filepath, map_location=config.DEVICE, weights_only=False)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    \n",
        "    if optimizer and \"optimizer_state_dict\" in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    if scheduler and \"scheduler_state_dict\" in checkpoint:\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "    if scaler and \"scaler_state_dict\" in checkpoint:\n",
        "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
        "    \n",
        "    return checkpoint[\"epoch\"], checkpoint.get(\"best_dice\", 0.0)\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# MAIN TRAINING LOOP\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def train(args):\n",
        "    \"\"\"Main training function.\"\"\"\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"BRAIN TUMOR SEGMENTATION — TRAINING\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Device: {config.DEVICE}\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    \n",
        "    # ── Create DataLoaders ─────────────────────────────────────────────\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(\n",
        "        subset_ratio=args.subset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "    )\n",
        "    \n",
        "    # ── Create Model ───────────────────────────────────────────────────\n",
        "    model = BrainTumorSegModel().to(config.DEVICE)\n",
        "    \n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\nModel: U-Net + {config.ENCODER_NAME}\")\n",
        "    print(f\"  Total params:     {total_params:,}\")\n",
        "    print(f\"  Trainable params: {trainable_params:,}\")\n",
        "    \n",
        "    # ── Loss, Optimizer, Scheduler ─────────────────────────────────────\n",
        "    criterion = CombinedLoss(seg_weight=0.8, cls_weight=0.2)\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=args.lr,\n",
        "        weight_decay=config.WEIGHT_DECAY,\n",
        "    )\n",
        "    scheduler = CosineWarmupScheduler(\n",
        "        optimizer,\n",
        "        warmup_epochs=config.WARMUP_EPOCHS,\n",
        "        total_epochs=args.epochs,\n",
        "    )\n",
        "    scaler = GradScaler('cuda', enabled=config.USE_AMP)\n",
        "    \n",
        "    # ── Resume from checkpoint if available ────────────────────────────\n",
        "    start_epoch = 0\n",
        "    best_dice = 0.0\n",
        "    \n",
        "    if args.resume:\n",
        "        ckpt_path = Path(args.resume)\n",
        "        if ckpt_path.exists():\n",
        "            print(f\"\\nResuming from checkpoint: {ckpt_path}\")\n",
        "            start_epoch, best_dice = load_checkpoint(\n",
        "                ckpt_path, model, optimizer, scheduler, scaler\n",
        "            )\n",
        "            start_epoch += 1  # Start from next epoch\n",
        "            print(f\"  Resuming from epoch {start_epoch}, best dice: {best_dice:.4f}\")\n",
        "    \n",
        "    # ── CSV Logger ─────────────────────────────────────────────────────\n",
        "    logger = CSVLogger(config.LOG_FILE)\n",
        "    \n",
        "    # ── GPU memory check after first batch ─────────────────────────────\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"\\n[GPU] Memory after model creation:\")\n",
        "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1024**2:.0f} MB\")\n",
        "        print(f\"  Cached:    {torch.cuda.memory_reserved() / 1024**2:.0f} MB\")\n",
        "    \n",
        "    # ── Training loop ──────────────────────────────────────────────────\n",
        "    patience_counter = 0\n",
        "    \n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"Starting training: {args.epochs - start_epoch} epochs\")\n",
        "    print(f\"  Batch size: {args.batch_size}\")\n",
        "    print(f\"  Grad accumulation: {config.GRAD_ACCUMULATION_STEPS}\")\n",
        "    print(f\"  Effective batch: {args.batch_size * config.GRAD_ACCUMULATION_STEPS}\")\n",
        "    print(f\"  Mixed precision: {config.USE_AMP}\")\n",
        "    print(f\"  Gradient checkpoint: {getattr(config, 'GRADIENT_CHECKPOINTING', False)}\")\n",
        "    print(f\"  Image size: {config.IMAGE_SIZE}x{config.IMAGE_SIZE}\")\n",
        "    print(f\"{'=' * 70}\\n\")\n",
        "    \n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        # ── Train ──────────────────────────────────────────────────\n",
        "        try:\n",
        "            train_metrics = train_one_epoch(\n",
        "                model, train_loader, criterion, optimizer, scaler,\n",
        "                config.DEVICE, config.GRAD_ACCUMULATION_STEPS,\n",
        "                epoch, args.epochs,\n",
        "            )\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(f\"\\n[OOM] GPU out of memory! Halving batch size...\")\n",
        "                torch.cuda.empty_cache()\n",
        "                args.batch_size = max(1, args.batch_size // 2)\n",
        "                print(f\"  New batch size: {args.batch_size}\")\n",
        "                print(f\"  Recreating DataLoaders...\")\n",
        "                train_loader, val_loader, test_loader = create_dataloaders(\n",
        "                    subset_ratio=args.subset,\n",
        "                    batch_size=args.batch_size,\n",
        "                    num_workers=args.num_workers,\n",
        "                )\n",
        "                continue  # Retry this epoch\n",
        "            raise\n",
        "        \n",
        "        # ── Validate ───────────────────────────────────────────────\n",
        "        val_metrics = validate(model, val_loader, criterion, config.DEVICE)\n",
        "        \n",
        "        # Free GPU memory after validation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        # ── Step scheduler ─────────────────────────────────────────\n",
        "        scheduler.step()\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start\n",
        "        \n",
        "        # ── Log metrics ────────────────────────────────────────────\n",
        "        logger.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"lr\": current_lr,\n",
        "            \"train_loss\": train_metrics[\"loss\"],\n",
        "            \"train_dice\": train_metrics[\"dice\"],\n",
        "            \"train_iou\": train_metrics[\"iou\"],\n",
        "            \"val_loss\": val_metrics[\"loss\"],\n",
        "            \"val_dice\": val_metrics[\"dice\"],\n",
        "            \"val_iou\": val_metrics[\"iou\"],\n",
        "            \"val_precision\": val_metrics[\"precision\"],\n",
        "            \"val_recall\": val_metrics[\"recall\"],\n",
        "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "            \"epoch_time_sec\": epoch_time,\n",
        "        })\n",
        "        \n",
        "        # ── Print epoch summary ────────────────────────────────────\n",
        "        print(f\"\\n{'─' * 70}\")\n",
        "        print(f\"Epoch {epoch+1}/{args.epochs}  ({epoch_time:.1f}s)  LR: {current_lr:.6f}\")\n",
        "        print(f\"  Train | Loss: {train_metrics['loss']:.4f} | \"\n",
        "              f\"Dice: {train_metrics['dice']:.4f} | IoU: {train_metrics['iou']:.4f}\")\n",
        "        print(f\"  Val   | Loss: {val_metrics['loss']:.4f} | \"\n",
        "              f\"Dice: {val_metrics['dice']:.4f} | IoU: {val_metrics['iou']:.4f} | \"\n",
        "              f\"Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f}\")\n",
        "        \n",
        "        # ── Save checkpoint ────────────────────────────────────────\n",
        "        ckpt_path = config.CHECKPOINT_DIR / f\"checkpoint_epoch_{epoch+1:03d}.pt\"\n",
        "        save_checkpoint(model, optimizer, scheduler, scaler, epoch, best_dice, ckpt_path)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_metrics[\"dice\"] > best_dice:\n",
        "            best_dice = val_metrics[\"dice\"]\n",
        "            best_path = config.CHECKPOINT_DIR / \"best_model.pt\"\n",
        "            save_checkpoint(model, optimizer, scheduler, scaler, epoch, best_dice, best_path)\n",
        "            print(f\"  >> New best model! Dice: {best_dice:.4f}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  >> No improvement. Patience: {patience_counter}/{config.EARLY_STOPPING_PATIENCE}\")\n",
        "        \n",
        "        # ── Early stopping ─────────────────────────────────────────\n",
        "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"\\n[EARLY STOPPING] No improvement for {config.EARLY_STOPPING_PATIENCE} epochs.\")\n",
        "            break\n",
        "    \n",
        "    # ── Final evaluation on test set ───────────────────────────────────\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(\"FINAL EVALUATION ON TEST SET\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    \n",
        "    # Load best model\n",
        "    best_path = config.CHECKPOINT_DIR / \"best_model.pt\"\n",
        "    if best_path.exists():\n",
        "        load_checkpoint(best_path, model)\n",
        "        print(f\"Loaded best model (Dice: {best_dice:.4f})\")\n",
        "    \n",
        "    test_metrics = validate(model, test_loader, criterion, config.DEVICE)\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"  Loss:      {test_metrics['loss']:.4f}\")\n",
        "    print(f\"  Dice:      {test_metrics['dice']:.4f}\")\n",
        "    print(f\"  IoU:       {test_metrics['iou']:.4f}\")\n",
        "    print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {test_metrics['recall']:.4f}\")\n",
        "    print(f\"  Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "    \n",
        "    # ── Export as TorchScript ──────────────────────────────────────────\n",
        "    print(f\"\\nExporting model to TorchScript...\")\n",
        "    model.eval()\n",
        "    model_cpu = model.to(\"cpu\")\n",
        "    example_input = torch.randn(1, 4, config.IMAGE_SIZE, config.IMAGE_SIZE)\n",
        "    \n",
        "    try:\n",
        "        traced = torch.jit.trace(model_cpu, example_input)\n",
        "        export_path = config.PROJECT_ROOT / \"brain_tumor_segmentation.pt\"\n",
        "        traced.save(str(export_path))\n",
        "        print(f\"  Model exported to: {export_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  [WARN] TorchScript tracing failed: {e}\")\n",
        "        print(f\"  Saving state_dict instead...\")\n",
        "        torch.save(model_cpu.state_dict(), config.PROJECT_ROOT / \"brain_tumor_segmentation_weights.pt\")\n",
        "    \n",
        "    print(f\"\\nTraining complete! Best validation Dice: {best_dice:.4f}\")\n",
        "    print(f\"Logs saved to: {config.LOG_FILE}\")\n",
        "    print(f\"Checkpoints in: {config.CHECKPOINT_DIR}\")\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CLI ENTRY POINT\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "if False: # __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train brain tumor segmentation model\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=config.EPOCHS,\n",
        "                        help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=config.BATCH_SIZE,\n",
        "                        help=\"Batch size per GPU\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=config.LEARNING_RATE,\n",
        "                        help=\"Initial learning rate\")\n",
        "    parser.add_argument(\"--subset\", type=float, default=config.SUBSET_RATIO,\n",
        "                        help=\"Fraction of patients to use (0.0-1.0)\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=config.NUM_WORKERS,\n",
        "                        help=\"DataLoader num_workers\")\n",
        "    parser.add_argument(\"--resume\", type=str, default=None,\n",
        "                        help=\"Path to checkpoint to resume from\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    train(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## evaluate.py\n",
        "\n",
        "Running content from `evaluate.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "EVALUATE — Test Set Evaluation & Visualization\n",
        "============================================================================\n",
        "Features:\n",
        "  - Test set evaluation with torch.no_grad()\n",
        "  - Confusion matrix generation\n",
        "  - Mask overlay visualization (predicted mask on original MRI)\n",
        "  - Training curves from CSV log\n",
        "  - Sample predictions grid\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Non-interactive backend (no GUI needed)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import torch\n",
        "from torch.amp import autocast\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    roc_curve, auc, ConfusionMatrixDisplay,\n",
        ")\n",
        "\n",
        "import config\n",
        "from dataset import create_dataloaders\n",
        "from model import BrainTumorSegModel, CombinedLoss, compute_metrics\n",
        "from train import load_checkpoint\n",
        "\n",
        "sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# 1. PLOT TRAINING CURVES\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def plot_training_curves(log_file: Path, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Reads the CSV training log and plots loss, Dice, IoU curves.\n",
        "    \"\"\"\n",
        "    epochs, train_loss, val_loss = [], [], []\n",
        "    train_dice, val_dice = [], []\n",
        "    train_iou, val_iou = [], []\n",
        "    lrs = []\n",
        "    \n",
        "    with open(log_file, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            epochs.append(int(row[\"epoch\"]))\n",
        "            train_loss.append(float(row[\"train_loss\"]))\n",
        "            val_loss.append(float(row[\"val_loss\"]))\n",
        "            train_dice.append(float(row[\"train_dice\"]))\n",
        "            val_dice.append(float(row[\"val_dice\"]))\n",
        "            train_iou.append(float(row[\"train_iou\"]))\n",
        "            val_iou.append(float(row[\"val_iou\"]))\n",
        "            lrs.append(float(row[\"lr\"]))\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(\"Training Progress\", fontsize=16, fontweight=\"bold\")\n",
        "    \n",
        "    # Loss\n",
        "    axes[0, 0].plot(epochs, train_loss, 'b-', label='Train', linewidth=2)\n",
        "    axes[0, 0].plot(epochs, val_loss, 'r-', label='Validation', linewidth=2)\n",
        "    axes[0, 0].set_title(\"Loss\")\n",
        "    axes[0, 0].set_xlabel(\"Epoch\")\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Dice\n",
        "    axes[0, 1].plot(epochs, train_dice, 'b-', label='Train', linewidth=2)\n",
        "    axes[0, 1].plot(epochs, val_dice, 'r-', label='Validation', linewidth=2)\n",
        "    axes[0, 1].set_title(\"Dice Coefficient\")\n",
        "    axes[0, 1].set_xlabel(\"Epoch\")\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # IoU\n",
        "    axes[1, 0].plot(epochs, train_iou, 'b-', label='Train', linewidth=2)\n",
        "    axes[1, 0].plot(epochs, val_iou, 'r-', label='Validation', linewidth=2)\n",
        "    axes[1, 0].set_title(\"IoU (Intersection over Union)\")\n",
        "    axes[1, 0].set_xlabel(\"Epoch\")\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Learning rate\n",
        "    axes[1, 1].plot(epochs, lrs, 'g-', linewidth=2)\n",
        "    axes[1, 1].set_title(\"Learning Rate Schedule\")\n",
        "    axes[1, 1].set_xlabel(\"Epoch\")\n",
        "    axes[1, 1].set_yscale(\"log\")\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    save_path = output_dir / \"training_curves.png\"\n",
        "    fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"[SAVED] Training curves: {save_path}\")\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# 2. CONFUSION MATRIX (per-slice classification)\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_confusion_matrix(model, test_loader, device, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Generates confusion matrix for slice-level tumor detection.\n",
        "    Each slice is classified as tumor/no-tumor based on the segmentation output.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    \n",
        "    for images, masks in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True)\n",
        "        \n",
        "        with autocast(device_type='cuda', enabled=config.USE_AMP):\n",
        "            seg_logits, cls_logits = model(images, return_classification=True)\n",
        "        \n",
        "        # Slice-level label: 1 if any tumor pixel exists\n",
        "        labels = (masks.sum(dim=(1, 2, 3)) > 0).cpu().numpy()\n",
        "        \n",
        "        # Slice-level prediction: 1 if predicted mask has tumor pixels\n",
        "        probs = torch.sigmoid(cls_logits).squeeze(-1).cpu().numpy()\n",
        "        preds = (probs > 0.5).astype(int)\n",
        "        \n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "        all_probs.extend(probs)\n",
        "        \n",
        "        del images, masks\n",
        "    \n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "    \n",
        "    # ── Confusion Matrix ──\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"No Tumor\", \"Tumor\"])\n",
        "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
        "    ax.set_title(\"Confusion Matrix (Slice-Level Classification)\", fontsize=14)\n",
        "    save_path = output_dir / \"confusion_matrix.png\"\n",
        "    fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"[SAVED] Confusion matrix: {save_path}\")\n",
        "    \n",
        "    # ── ROC Curve ──\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "    ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {roc_auc:.4f}')\n",
        "    ax.plot([0, 1], [0, 1], 'r--', linewidth=1)\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(\"ROC Curve (Slice-Level)\", fontsize=14)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    save_path = output_dir / \"roc_curve.png\"\n",
        "    fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"[SAVED] ROC curve: {save_path}\")\n",
        "    \n",
        "    # ── Classification Report ──\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                    target_names=[\"No Tumor\", \"Tumor\"])\n",
        "    print(f\"\\nClassification Report:\\n{report}\")\n",
        "    print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
        "    \n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# 3. SAMPLE PREDICTIONS WITH MASK OVERLAY\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_sample_predictions(model, test_loader, device, output_dir: Path, n_samples=10):\n",
        "    \"\"\"\n",
        "    Generates overlay visualizations: original MRI + ground truth + prediction.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    samples_collected = 0\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4 * n_samples))\n",
        "    fig.suptitle(\"Sample Predictions\", fontsize=16, fontweight=\"bold\", y=1.01)\n",
        "    \n",
        "    column_titles = [\"T1c Input\", \"Ground Truth Mask\", \"Predicted Mask\", \"Overlay\"]\n",
        "    \n",
        "    for images, masks in test_loader:\n",
        "        if samples_collected >= n_samples:\n",
        "            break\n",
        "        \n",
        "        images = images.to(device, non_blocking=True)\n",
        "        with autocast(device_type='cuda', enabled=config.USE_AMP):\n",
        "            seg_logits = model(images)\n",
        "        \n",
        "        seg_probs = torch.sigmoid(seg_logits).cpu().numpy()\n",
        "        images_np = images.cpu().numpy()\n",
        "        masks_np = masks.cpu().numpy()\n",
        "        \n",
        "        for i in range(images.shape[0]):\n",
        "            if samples_collected >= n_samples:\n",
        "                break\n",
        "            \n",
        "            idx = samples_collected\n",
        "            \n",
        "            # T1c channel (first modality) for display\n",
        "            t1c = images_np[i, 0]  # (H, W)\n",
        "            gt_mask = masks_np[i, 0]  # (H, W)\n",
        "            pred_mask = seg_probs[i, 0]  # (H, W)\n",
        "            pred_binary = (pred_mask > 0.5).astype(float)\n",
        "            \n",
        "            # Normalize T1c for display\n",
        "            t1c_display = (t1c - t1c.min()) / (t1c.max() - t1c.min() + 1e-8)\n",
        "            \n",
        "            # Column 1: T1c slice\n",
        "            axes[idx, 0].imshow(t1c_display, cmap='gray')\n",
        "            axes[idx, 0].set_title(column_titles[0] if idx == 0 else \"\")\n",
        "            axes[idx, 0].axis('off')\n",
        "            \n",
        "            # Column 2: Ground truth mask\n",
        "            axes[idx, 1].imshow(t1c_display, cmap='gray')\n",
        "            axes[idx, 1].imshow(gt_mask, cmap='Reds', alpha=0.5)\n",
        "            axes[idx, 1].set_title(column_titles[1] if idx == 0 else \"\")\n",
        "            axes[idx, 1].axis('off')\n",
        "            \n",
        "            # Column 3: Predicted mask\n",
        "            axes[idx, 2].imshow(t1c_display, cmap='gray')\n",
        "            axes[idx, 2].imshow(pred_binary, cmap='Blues', alpha=0.5)\n",
        "            axes[idx, 2].set_title(column_titles[2] if idx == 0 else \"\")\n",
        "            axes[idx, 2].axis('off')\n",
        "            \n",
        "            # Column 4: Overlay (green=TP, red=FN, blue=FP)\n",
        "            overlay = np.zeros((*t1c_display.shape, 3))\n",
        "            overlay[..., :] = np.stack([t1c_display]*3, axis=-1)\n",
        "            overlay[gt_mask > 0, 1] = 0.7  # Ground truth in green\n",
        "            overlay[pred_binary > 0, 2] = 0.7  # Prediction in blue\n",
        "            overlay[(gt_mask > 0) & (pred_binary > 0), :] = [0, 1, 0]  # TP in bright green\n",
        "            overlay[(gt_mask > 0) & (pred_binary == 0), :] = [1, 0, 0]  # FN in red\n",
        "            overlay[(gt_mask == 0) & (pred_binary > 0), :] = [0, 0, 1]  # FP in blue\n",
        "            \n",
        "            axes[idx, 3].imshow(np.clip(overlay, 0, 1))\n",
        "            axes[idx, 3].set_title(column_titles[3] if idx == 0 else \"\")\n",
        "            axes[idx, 3].axis('off')\n",
        "            \n",
        "            # Dice for this sample\n",
        "            dice = compute_metrics(\n",
        "                torch.tensor(pred_mask).unsqueeze(0).unsqueeze(0),\n",
        "                torch.tensor(gt_mask).unsqueeze(0).unsqueeze(0),\n",
        "            )[\"dice\"]\n",
        "            axes[idx, 0].set_ylabel(f\"Sample {idx+1}\\nDice: {dice:.3f}\", fontsize=10)\n",
        "            \n",
        "            samples_collected += 1\n",
        "        \n",
        "        del images, masks\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    save_path = output_dir / \"sample_predictions.png\"\n",
        "    fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"[SAVED] Sample predictions: {save_path}\")\n",
        "    \n",
        "    # Save individual overlay images\n",
        "    overlay_dir = output_dir / \"overlays\"\n",
        "    overlay_dir.mkdir(exist_ok=True)\n",
        "    print(f\"[INFO] Individual overlays saved to: {overlay_dir}\")\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# MAIN EVALUATION ENTRY POINT\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def evaluate(args):\n",
        "    \"\"\"Run full evaluation pipeline.\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"BRAIN TUMOR SEGMENTATION - EVALUATION\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    output_dir = config.OUTPUT_DIR\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # ── Plot training curves ──\n",
        "    if config.LOG_FILE.exists():\n",
        "        print(\"\\n[1/3] Plotting training curves...\")\n",
        "        plot_training_curves(config.LOG_FILE, output_dir)\n",
        "    else:\n",
        "        print(f\"[SKIP] No training log found at {config.LOG_FILE}\")\n",
        "    \n",
        "    # ── Load model ──\n",
        "    print(\"\\n[2/3] Loading best model...\")\n",
        "    model = BrainTumorSegModel().to(config.DEVICE)\n",
        "    \n",
        "    ckpt_path = Path(args.checkpoint) if args.checkpoint else config.CHECKPOINT_DIR / \"best_model.pt\"\n",
        "    if ckpt_path.exists():\n",
        "        epoch, best_dice = load_checkpoint(ckpt_path, model)\n",
        "        print(f\"  Loaded from: {ckpt_path}\")\n",
        "        print(f\"  Epoch: {epoch+1}, Best Dice: {best_dice:.4f}\")\n",
        "    else:\n",
        "        print(f\"  [ERROR] Checkpoint not found: {ckpt_path}\")\n",
        "        return\n",
        "    \n",
        "    # ── Create test DataLoader ──\n",
        "    _, _, test_loader = create_dataloaders(\n",
        "        subset_ratio=args.subset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "    )\n",
        "    \n",
        "    # ── Full test evaluation ──\n",
        "    print(\"\\n[3/3] Running evaluation...\")\n",
        "    criterion = CombinedLoss()\n",
        "    \n",
        "    from train import validate\n",
        "    test_metrics = validate(model, test_loader, criterion, config.DEVICE)\n",
        "    \n",
        "    print(f\"\\n{'=' * 50}\")\n",
        "    print(f\"TEST RESULTS\")\n",
        "    print(f\"{'=' * 50}\")\n",
        "    for k, v in test_metrics.items():\n",
        "        print(f\"  {k:>12s}: {v:.4f}\")\n",
        "    \n",
        "    # ── Confusion matrix & ROC ──\n",
        "    print(\"\\nGenerating confusion matrix and ROC curve...\")\n",
        "    roc_auc = generate_confusion_matrix(model, test_loader, config.DEVICE, output_dir)\n",
        "    \n",
        "    # ── Sample predictions ──\n",
        "    print(\"\\nGenerating sample predictions...\")\n",
        "    generate_sample_predictions(model, test_loader, config.DEVICE, output_dir,\n",
        "                                n_samples=args.n_samples)\n",
        "    \n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"Evaluation complete! Results saved to: {output_dir}\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "\n",
        "if False: # __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Evaluate brain tumor segmentation model\")\n",
        "    parser.add_argument(\"--checkpoint\", type=str, default=None,\n",
        "                        help=\"Path to model checkpoint\")\n",
        "    parser.add_argument(\"--subset\", type=float, default=1.0,\n",
        "                        help=\"Dataset subset ratio for evaluation\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=config.BATCH_SIZE,\n",
        "                        help=\"Batch size\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=config.NUM_WORKERS,\n",
        "                        help=\"DataLoader workers\")\n",
        "    parser.add_argument(\"--n_samples\", type=int, default=10,\n",
        "                        help=\"Number of sample predictions to visualize\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    evaluate(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## inference.py\n",
        "\n",
        "Running content from `inference.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "INFERENCE — Single-Image Prediction Pipeline\n",
        "============================================================================\n",
        "Usage:\n",
        "    python inference.py --input \"Data/PatientID_0003/Timepoint_1\" --output \"results/\"\n",
        "\n",
        "Input: Path to a timepoint folder containing 4 MRI modality NIfTI files\n",
        "Output: \n",
        "  - Per-slice tumor masks saved as PNGs\n",
        "  - Overlay visualizations\n",
        "  - Classification result (cancerous / non-cancerous) with confidence\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.amp import autocast\n",
        "\n",
        "import config\n",
        "\n",
        "sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "\n",
        "def load_model(checkpoint_path: str = None):\n",
        "    \"\"\"\n",
        "    Load the trained model from checkpoint.\n",
        "    Tries TorchScript first, falls back to state_dict.\n",
        "    \"\"\"\n",
        "    # Try TorchScript model first\n",
        "    ts_path = config.PROJECT_ROOT / \"brain_tumor_segmentation.pt\"\n",
        "    if ts_path.exists() and checkpoint_path is None:\n",
        "        print(f\"[MODEL] Loading TorchScript model: {ts_path}\")\n",
        "        model = torch.jit.load(str(ts_path), map_location=config.DEVICE)\n",
        "        model.eval()\n",
        "        return model, \"torchscript\"\n",
        "    \n",
        "    # Fall back to checkpoint\n",
        "    from model import BrainTumorSegModel\n",
        "    model = BrainTumorSegModel().to(config.DEVICE)\n",
        "    \n",
        "    ckpt_path = Path(checkpoint_path) if checkpoint_path else config.CHECKPOINT_DIR / \"best_model.pt\"\n",
        "    if ckpt_path.exists():\n",
        "        print(f\"[MODEL] Loading checkpoint: {ckpt_path}\")\n",
        "        checkpoint = torch.load(ckpt_path, map_location=config.DEVICE, weights_only=False)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    else:\n",
        "        print(f\"[ERROR] No model found at {ckpt_path}\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    model.eval()\n",
        "    return model, \"checkpoint\"\n",
        "\n",
        "\n",
        "def load_timepoint_data(timepoint_dir: Path):\n",
        "    \"\"\"\n",
        "    Load all 4 MRI modalities from a timepoint directory.\n",
        "    Returns: (volume_4d, affine) where volume_4d is (H, W, D, 4)\n",
        "    \"\"\"\n",
        "    modality_volumes = []\n",
        "    \n",
        "    for mod in config.MODALITY_SUFFIXES:\n",
        "        # Find the file matching this modality\n",
        "        matching = list(timepoint_dir.glob(f\"*{mod}.nii.gz\"))\n",
        "        if not matching:\n",
        "            raise FileNotFoundError(f\"Missing modality {mod} in {timepoint_dir}\")\n",
        "        \n",
        "        nii = nib.load(str(matching[0]))\n",
        "        vol = nii.get_fdata(dtype=np.float32)\n",
        "        modality_volumes.append(vol)\n",
        "        affine = nii.affine\n",
        "    \n",
        "    # Stack as (H, W, D, 4)\n",
        "    volume_4d = np.stack(modality_volumes, axis=-1)\n",
        "    return volume_4d, affine\n",
        "\n",
        "\n",
        "def normalize_slice(slice_4ch):\n",
        "    \"\"\"Z-score normalize each channel of a 2D slice.\"\"\"\n",
        "    normalized = np.copy(slice_4ch)\n",
        "    for c in range(slice_4ch.shape[-1]):\n",
        "        ch = normalized[:, :, c]\n",
        "        nonzero = ch[ch > 0]\n",
        "        if len(nonzero) > 0:\n",
        "            mean = nonzero.mean()\n",
        "            std = nonzero.std() + 1e-8\n",
        "            ch[ch > 0] = (ch[ch > 0] - mean) / std\n",
        "        normalized[:, :, c] = ch\n",
        "    return normalized\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_volume(model, volume_4d, model_type=\"checkpoint\"):\n",
        "    \"\"\"\n",
        "    Run inference on an entire 3D volume, slice by slice.\n",
        "    \n",
        "    Args:\n",
        "        model: trained model\n",
        "        volume_4d: (H, W, D, 4) numpy array\n",
        "        model_type: \"torchscript\" or \"checkpoint\"\n",
        "    \n",
        "    Returns:\n",
        "        predictions: (H_out, W_out, D) probability map\n",
        "        classifications: (D,) per-slice cancer probability\n",
        "    \"\"\"\n",
        "    H, W, D, C = volume_4d.shape\n",
        "    predictions = np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE, D), dtype=np.float32)\n",
        "    classifications = np.zeros(D, dtype=np.float32)\n",
        "    \n",
        "    for z in range(D):\n",
        "        slice_4ch = volume_4d[:, :, z, :]  # (H, W, 4)\n",
        "        \n",
        "        # Skip mostly-empty slices\n",
        "        brain_fraction = np.count_nonzero(slice_4ch[:, :, 0]) / (H * W)\n",
        "        if brain_fraction < config.MIN_BRAIN_FRACTION:\n",
        "            continue\n",
        "        \n",
        "        # Normalize\n",
        "        slice_norm = normalize_slice(slice_4ch)\n",
        "        \n",
        "        # Resize to model input size\n",
        "        from skimage.transform import resize\n",
        "        slice_resized = resize(slice_norm, (config.IMAGE_SIZE, config.IMAGE_SIZE, C),\n",
        "                               preserve_range=True, anti_aliasing=True)\n",
        "        \n",
        "        # To tensor: (1, 4, H, W)\n",
        "        tensor = torch.from_numpy(slice_resized.transpose(2, 0, 1)).unsqueeze(0).float()\n",
        "        tensor = tensor.to(config.DEVICE)\n",
        "        \n",
        "        with autocast(device_type='cuda', enabled=config.USE_AMP and config.DEVICE.type == 'cuda'):\n",
        "            if model_type == \"torchscript\":\n",
        "                seg_logits = model(tensor)\n",
        "                cls_prob = 0.0  # TorchScript may not support dual output\n",
        "            else:\n",
        "                seg_logits, cls_logits = model(tensor, return_classification=True)\n",
        "                cls_prob = torch.sigmoid(cls_logits).item()\n",
        "        \n",
        "        seg_prob = torch.sigmoid(seg_logits).squeeze().cpu().numpy()\n",
        "        predictions[:, :, z] = seg_prob\n",
        "        classifications[z] = cls_prob\n",
        "    \n",
        "    return predictions, classifications\n",
        "\n",
        "\n",
        "def generate_visualizations(volume_4d, predictions, classifications, output_dir: Path):\n",
        "    \"\"\"\n",
        "    Generate overlay visualizations for each clinically relevant slice.\n",
        "    \"\"\"\n",
        "    H, W, D, C = volume_4d.shape\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Find slices with significant predictions\n",
        "    tumor_slices = []\n",
        "    for z in range(D):\n",
        "        pred_slice = predictions[:, :, z]\n",
        "        if pred_slice.max() > 0.3:  # At least some tumor probability\n",
        "            tumor_slices.append((z, pred_slice.max()))\n",
        "    \n",
        "    tumor_slices.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    print(f\"\\n[VIS] Found {len(tumor_slices)} slices with tumor predictions\")\n",
        "    \n",
        "    # Generate overlay for top slices\n",
        "    n_show = min(20, len(tumor_slices))\n",
        "    \n",
        "    if n_show > 0:\n",
        "        fig, axes = plt.subplots(n_show, 3, figsize=(12, 4 * n_show))\n",
        "        if n_show == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        \n",
        "        for i, (z, max_prob) in enumerate(tumor_slices[:n_show]):\n",
        "            from skimage.transform import resize\n",
        "            t1c = volume_4d[:, :, z, 0]\n",
        "            t1c_resized = resize(t1c, (config.IMAGE_SIZE, config.IMAGE_SIZE),\n",
        "                                 preserve_range=True, anti_aliasing=True)\n",
        "            t1c_display = (t1c_resized - t1c_resized.min()) / (t1c_resized.max() - t1c_resized.min() + 1e-8)\n",
        "            \n",
        "            pred = predictions[:, :, z]\n",
        "            pred_binary = (pred > 0.5).astype(float)\n",
        "            \n",
        "            # Original\n",
        "            axes[i, 0].imshow(t1c_display, cmap='gray')\n",
        "            axes[i, 0].set_title(f\"Slice {z} - T1c\" if i == 0 else f\"Slice {z}\")\n",
        "            axes[i, 0].axis('off')\n",
        "            \n",
        "            # Prediction heatmap\n",
        "            axes[i, 1].imshow(t1c_display, cmap='gray')\n",
        "            axes[i, 1].imshow(pred, cmap='hot', alpha=0.6, vmin=0, vmax=1)\n",
        "            axes[i, 1].set_title(\"Tumor Probability\" if i == 0 else \"\")\n",
        "            axes[i, 1].axis('off')\n",
        "            \n",
        "            # Binary overlay\n",
        "            overlay = np.stack([t1c_display]*3, axis=-1)\n",
        "            overlay[pred_binary > 0] = [1, 0.2, 0.2]  # Red for tumor\n",
        "            axes[i, 2].imshow(np.clip(overlay, 0, 1))\n",
        "            axes[i, 2].set_title(\"Tumor Region\" if i == 0 else \"\")\n",
        "            axes[i, 2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        save_path = output_dir / \"tumor_overlay_grid.png\"\n",
        "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        print(f\"[SAVED] Tumor overlay grid: {save_path}\")\n",
        "    \n",
        "    # Save individual overlays for the top 5 slices\n",
        "    for i, (z, max_prob) in enumerate(tumor_slices[:5]):\n",
        "        from skimage.transform import resize\n",
        "        t1c = volume_4d[:, :, z, 0]\n",
        "        t1c_resized = resize(t1c, (config.IMAGE_SIZE, config.IMAGE_SIZE),\n",
        "                             preserve_range=True, anti_aliasing=True)\n",
        "        t1c_display = (t1c_resized - t1c_resized.min()) / (t1c_resized.max() - t1c_resized.min() + 1e-8)\n",
        "        pred = predictions[:, :, z]\n",
        "        \n",
        "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "        ax.imshow(t1c_display, cmap='gray')\n",
        "        ax.imshow(pred, cmap='hot', alpha=0.5, vmin=0, vmax=1)\n",
        "        ax.set_title(f\"Slice {z} | Tumor Prob: {max_prob:.2f}\")\n",
        "        ax.axis('off')\n",
        "        \n",
        "        save_path = output_dir / f\"overlay_slice_{z:03d}.png\"\n",
        "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "    \n",
        "    print(f\"[SAVED] Individual overlays in: {output_dir}\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"Main inference pipeline.\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"BRAIN TUMOR SEGMENTATION - INFERENCE\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    input_dir = Path(args.input)\n",
        "    output_dir = Path(args.output)\n",
        "    \n",
        "    if not input_dir.exists():\n",
        "        print(f\"[ERROR] Input directory not found: {input_dir}\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    # ── Load model ──\n",
        "    model, model_type = load_model(args.checkpoint)\n",
        "    print(f\"  Model type: {model_type}\")\n",
        "    \n",
        "    # ── Load MRI data ──\n",
        "    print(f\"\\n[DATA] Loading MRI from: {input_dir}\")\n",
        "    volume_4d, affine = load_timepoint_data(input_dir)\n",
        "    print(f\"  Volume shape: {volume_4d.shape}\")\n",
        "    print(f\"  Modalities: {config.MODALITY_SUFFIXES}\")\n",
        "    \n",
        "    # ── Run prediction ──\n",
        "    print(f\"\\n[PREDICT] Running inference on {volume_4d.shape[2]} slices...\")\n",
        "    predictions, classifications = predict_volume(model, volume_4d, model_type)\n",
        "    \n",
        "    # ── Overall classification ──\n",
        "    # Average classification confidence across all valid slices\n",
        "    valid_cls = classifications[classifications > 0]\n",
        "    if len(valid_cls) > 0:\n",
        "        avg_confidence = valid_cls.mean()\n",
        "        max_confidence = valid_cls.max()\n",
        "    else:\n",
        "        avg_confidence = 0.0\n",
        "        max_confidence = 0.0\n",
        "    \n",
        "    is_cancerous = max_confidence > 0.5\n",
        "    \n",
        "    # Count tumor voxels in prediction\n",
        "    tumor_volume = (predictions > 0.5).sum()\n",
        "    total_volume = predictions.size\n",
        "    tumor_fraction = tumor_volume / total_volume\n",
        "    \n",
        "    print(f\"\\n{'=' * 50}\")\n",
        "    print(f\"DIAGNOSIS RESULT\")\n",
        "    print(f\"{'=' * 50}\")\n",
        "    print(f\"  Classification:     {'CANCEROUS' if is_cancerous else 'NON-CANCEROUS'}\")\n",
        "    print(f\"  Max Confidence:     {max_confidence:.4f}\")\n",
        "    print(f\"  Avg Confidence:     {avg_confidence:.4f}\")\n",
        "    print(f\"  Tumor volume:       {tumor_volume} voxels ({tumor_fraction*100:.2f}% of brain)\")\n",
        "    print(f\"  Affected slices:    {(predictions.max(axis=(0,1)) > 0.5).sum()}/{volume_4d.shape[2]}\")\n",
        "    \n",
        "    # ── Generate visualizations ──\n",
        "    print(f\"\\n[VIS] Generating visualizations...\")\n",
        "    generate_visualizations(volume_4d, predictions, classifications, output_dir)\n",
        "    \n",
        "    # ── Save prediction as NIfTI ──\n",
        "    pred_nii_path = output_dir / \"predicted_mask.nii.gz\"\n",
        "    from skimage.transform import resize\n",
        "    # Resize back to original dimensions\n",
        "    pred_full = resize(predictions, volume_4d.shape[:3], preserve_range=True, anti_aliasing=True)\n",
        "    pred_nii = nib.Nifti1Image((pred_full > 0.5).astype(np.uint8), affine)\n",
        "    nib.save(pred_nii, str(pred_nii_path))\n",
        "    print(f\"[SAVED] Predicted mask NIfTI: {pred_nii_path}\")\n",
        "    \n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"Inference complete! Results saved to: {output_dir}\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    \n",
        "    # ── Clinical disclaimer ──\n",
        "    print(f\"\"\"\n",
        " ** IMPORTANT DISCLAIMER **\n",
        " This model is for research and competition purposes only.\n",
        " It has NOT been clinically validated and should NEVER be used\n",
        " as the sole basis for medical diagnosis or treatment decisions.\n",
        " Always consult qualified medical professionals.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "if False: # __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Run inference on a brain MRI scan\")\n",
        "    parser.add_argument(\"--input\", type=str, required=True,\n",
        "                        help=\"Path to timepoint folder with MRI NIfTI files\")\n",
        "    parser.add_argument(\"--output\", type=str, default=\"inference_output\",\n",
        "                        help=\"Output directory for results\")\n",
        "    parser.add_argument(\"--checkpoint\", type=str, default=None,\n",
        "                        help=\"Path to model checkpoint (optional)\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    main(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execution Instructions\n",
        "\n",
        "The code above defines all necessary classes and functions.\n",
        "Use the cells below to run training, evaluation, or inference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model (Example: 5% subset for quick test)\n",
        "# To train on full dataset, set subset=1.0 and epochs=50+\n",
        "\n",
        "class Args:\n",
        "    epochs = 2\n",
        "    batch_size = 4\n",
        "    lr = 1e-3\n",
        "    subset = 0.05\n",
        "    num_workers = 0  # 0 for safe Windows interaction in notebook\n",
        "    resume = None\n",
        "\n",
        "args = Args()\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        train(args)\n",
        "    except SystemExit:\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# (Assumes 'checkpoints/best_model.pt' exists after training)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        evaluate_args = argparse.Namespace(\n",
        "            checkpoint=None,\n",
        "            subset=0.05,\n",
        "            batch_size=4,\n",
        "            num_workers=0,\n",
        "            n_samples=5\n",
        "        )\n",
        "        evaluate(evaluate_args)\n",
        "    except SystemExit:\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation error (maybe model not trained yet?): {e}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}